{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "keras-grid-search.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/morbosohex/Workflow/blob/master/keras_grid_search.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hn3wSM6aE4YG",
        "colab_type": "text"
      },
      "source": [
        "# How to Use Keras Models in scikit-learn\n",
        "\n",
        "使用KerasClassifier或者KerasRegressor类,  定义一个函数创建和返回Keras序列模型, 然后将这个函数传输给build_fn参数\n",
        "\n",
        "```\n",
        "def create_model():\n",
        "\t...\n",
        "\treturn model\n",
        " \n",
        "model = KerasClassifier(build_fn=create_model)\n",
        "```\n",
        "KerasClassifier类的构造函数可以采用传递调用 model.fit()的默认参数,例如epochs数和批处理大小。\n",
        "\n",
        "```\n",
        "def create_model():\n",
        "\t...\n",
        "\treturn model\n",
        "\n",
        "model = KerasClassifier(build_fn=create_model, epochs=10)\n",
        "```\n",
        "\n",
        "KerasClassifier‎‎类的构造函数还可以传递自定义参数, 这些参数是在‎‎create_model()‎‎函数中进行定义。\n",
        "\n",
        "```\n",
        "\n",
        "def create_model(dropout_rate=0.0):\n",
        "\t...\n",
        "\treturn model\n",
        " \n",
        "model = KerasClassifier(build_fn=create_model, dropout_rate=0.2)\n",
        "```\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G45UhjKgG6Na",
        "colab_type": "text"
      },
      "source": [
        "# How to Use Grid Search in scikit-learn\n",
        "\n",
        "GridSearchCV class\n",
        "\n",
        "‎构造此类时,必须提供超参数字典,模型参数名称和要尝试的值。‎\n",
        "\n",
        "优化目标默认是accuracy, 当然其他的值也可以被指定, 通过给`score`进行赋值\n",
        "\n",
        "‎默认情况下,网格搜索将仅使用一个线程。通过将‎‎GridSearchCV‎‎构造函数中的‎‎n_jobs‎‎参数设置为 -1,进程将使用计算机上的所有核。\n",
        "\n",
        "‎然后,GridSearchCV‎‎进程将为每个参数组合构造和评估一个模型。交叉验证用于评估每个单独的模型,并使用 3 倍交叉验证的默认值,尽管可以通过将‎‎cv‎‎参数指定到‎‎GridSearchCV‎‎构造函数来覆盖这一点\n",
        "\n",
        "```\n",
        "param_grid = dict(epochs=[10,20,30])\n",
        "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1)\n",
        "grid_result = grid.fit(X, Y)\n",
        "```\n",
        "\n",
        "‎完成后,您可以在从‎‎grid.fit()‎‎返回的结果对象中访问网格搜索的结果。‎‎Best_Score_‎‎成员提供对优化过程中观察到的最佳分数的访问"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZFiN53J6JEXc",
        "colab_type": "text"
      },
      "source": [
        "# How to Tune Batch Size and Number of Epochs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uMZeJ_bEExsi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Use scikit-learn to grid search the batch size and epochs\n",
        "import numpy \n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "\n",
        "# Function to create model, required for KerasClassifier\n",
        "def create_model():\n",
        "    # create model\n",
        "    model = Sequential()\n",
        "    model.add(Dense(12, input_dim=8, activation='relu'))\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "    \n",
        "    # compile model\n",
        "    model.compile(loss='binary_crossentropy',\n",
        "                  optimizer='adam',\n",
        "                  metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "# Fix random seed for reproducibility\n",
        "seed = 7\n",
        "numpy.random.seed(seed)\n",
        "\n",
        "# load dataset\n",
        "dataset = numpy.loadtxt(\"pima-indians-diabetes.csv\", delimiter=\",\")\n",
        "\n",
        "# split into input (X) and output (Y) variables\n",
        "X = dataset[:,0:8]\n",
        "Y = dataset[:,8]\n",
        "\n",
        "# Create model\n",
        "model = KerasClassifier(build_fn=create_model, verbose=0)\n",
        "\n",
        "# define the grid search parameters\n",
        "batch_size = [10,20,40, 60, 80, 100]\n",
        "epochs = [10,50,100]\n",
        "param_grid = dict(batch_size=batch_size, epochs=epochs)\n",
        "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1)\n",
        "grid_result = grid.fit(X,Y)\n",
        "\n",
        "# summarize results\n",
        "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
        "means = grid_result.cv_results_['mean_test_score']\n",
        "stds = grid_result.cv_results_['std_test_score']\n",
        "params = grid_result.cv_results_['params']\n",
        "\n",
        "for mean, stdev, param in zip(means, stds, params):\n",
        "    print(f'{mean} ({std}) with : {param}')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ro09jAzNQiCW",
        "colab_type": "text"
      },
      "source": [
        "# How to Tune the Training Optimization Algorithm"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ewOe1gjEQkOi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Use scikit-learn to grid search the batch size and epochs\n",
        "import numpy\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "# Function to create model, required for KerasClassifier\n",
        "def create_model(optimizer='adam'):\n",
        "\t# create model\n",
        "\tmodel = Sequential()\n",
        "\tmodel.add(Dense(12, input_dim=8, activation='relu'))\n",
        "\tmodel.add(Dense(1, activation='sigmoid'))\n",
        "\t# Compile model\n",
        "\tmodel.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
        "\treturn model\n",
        "# fix random seed for reproducibility\n",
        "seed = 7\n",
        "numpy.random.seed(seed)\n",
        "# load dataset\n",
        "dataset = numpy.loadtxt(\"pima-indians-diabetes.csv\", delimiter=\",\")\n",
        "# split into input (X) and output (Y) variables\n",
        "X = dataset[:,0:8]\n",
        "Y = dataset[:,8]\n",
        "# create model\n",
        "model = KerasClassifier(build_fn=create_model, epochs=100, batch_size=10, verbose=0)\n",
        "# define the grid search parameters\n",
        "optimizer = ['SGD', 'RMSprop', 'Adagrad', 'Adadelta', 'Adam', 'Adamax', 'Nadam']\n",
        "param_grid = dict(optimizer=optimizer)\n",
        "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1)\n",
        "grid_result = grid.fit(X, Y)\n",
        "# summarize results\n",
        "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
        "means = grid_result.cv_results_['mean_test_score']\n",
        "stds = grid_result.cv_results_['std_test_score']\n",
        "params = grid_result.cv_results_['params']\n",
        "for mean, stdev, param in zip(means, stds, params):\n",
        "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DlL6HcTiQqai",
        "colab_type": "text"
      },
      "source": [
        "# How to Tune Learning Rate and Momentum"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b7CZ7XR9QsuC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Use scikit-learn to grid search the learning rate and momentum\n",
        "import numpy\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "from keras.optimizers import SGD\n",
        "# Function to create model, required for KerasClassifier\n",
        "def create_model(learn_rate=0.01, momentum=0):\n",
        "\t# create model\n",
        "\tmodel = Sequential()\n",
        "\tmodel.add(Dense(12, input_dim=8, activation='relu'))\n",
        "\tmodel.add(Dense(1, activation='sigmoid'))\n",
        "\t# Compile model\n",
        "\toptimizer = SGD(lr=learn_rate, momentum=momentum)\n",
        "\tmodel.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
        "\treturn model\n",
        "# fix random seed for reproducibility\n",
        "seed = 7\n",
        "numpy.random.seed(seed)\n",
        "# load dataset\n",
        "dataset = numpy.loadtxt(\"pima-indians-diabetes.csv\", delimiter=\",\")\n",
        "# split into input (X) and output (Y) variables\n",
        "X = dataset[:,0:8]\n",
        "Y = dataset[:,8]\n",
        "# create model\n",
        "model = KerasClassifier(build_fn=create_model, epochs=100, batch_size=10, verbose=0)\n",
        "# define the grid search parameters\n",
        "learn_rate = [0.001, 0.01, 0.1, 0.2, 0.3]\n",
        "momentum = [0.0, 0.2, 0.4, 0.6, 0.8, 0.9]\n",
        "param_grid = dict(learn_rate=learn_rate, momentum=momentum)\n",
        "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1)\n",
        "grid_result = grid.fit(X, Y)\n",
        "# summarize results\n",
        "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
        "means = grid_result.cv_results_['mean_test_score']\n",
        "stds = grid_result.cv_results_['std_test_score']\n",
        "params = grid_result.cv_results_['params']\n",
        "for mean, stdev, param in zip(means, stds, params):\n",
        "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hwsv8JxeQ1gq",
        "colab_type": "text"
      },
      "source": [
        "# How to Tune Network Weight Initialization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WvIkd1wPQ3M5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Use scikit-learn to grid search the weight initialization\n",
        "import numpy\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "# Function to create model, required for KerasClassifier\n",
        "def create_model(init_mode='uniform'):\n",
        "\t# create model\n",
        "\tmodel = Sequential()\n",
        "\tmodel.add(Dense(12, input_dim=8, kernel_initializer=init_mode, activation='relu'))\n",
        "\tmodel.add(Dense(1, kernel_initializer=init_mode, activation='sigmoid'))\n",
        "\t# Compile model\n",
        "\tmodel.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\treturn model\n",
        "# fix random seed for reproducibility\n",
        "seed = 7\n",
        "numpy.random.seed(seed)\n",
        "# load dataset\n",
        "dataset = numpy.loadtxt(\"pima-indians-diabetes.csv\", delimiter=\",\")\n",
        "# split into input (X) and output (Y) variables\n",
        "X = dataset[:,0:8]\n",
        "Y = dataset[:,8]\n",
        "# create model\n",
        "model = KerasClassifier(build_fn=create_model, epochs=100, batch_size=10, verbose=0)\n",
        "# define the grid search parameters\n",
        "init_mode = ['uniform', 'lecun_uniform', 'normal', 'zero', 'glorot_normal', 'glorot_uniform', 'he_normal', 'he_uniform']\n",
        "param_grid = dict(init_mode=init_mode)\n",
        "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1)\n",
        "grid_result = grid.fit(X, Y)\n",
        "# summarize results\n",
        "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
        "means = grid_result.cv_results_['mean_test_score']\n",
        "stds = grid_result.cv_results_['std_test_score']\n",
        "params = grid_result.cv_results_['params']\n",
        "for mean, stdev, param in zip(means, stds, params):\n",
        "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XSqGv4DnQ-ds",
        "colab_type": "text"
      },
      "source": [
        "# How to Tune the Neuron Activation Function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FNIfvJuFQ_xD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "# Function to create model, required for KerasClassifier\n",
        "def create_model(activation='relu'):\n",
        "\t# create model\n",
        "\tmodel = Sequential()\n",
        "\tmodel.add(Dense(12, input_dim=8, kernel_initializer='uniform', activation=activation))\n",
        "\tmodel.add(Dense(1, kernel_initializer='uniform', activation='sigmoid'))\n",
        "\t# Compile model\n",
        "\tmodel.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\treturn model\n",
        "# fix random seed for reproducibility\n",
        "seed = 7\n",
        "numpy.random.seed(seed)\n",
        "# load dataset\n",
        "dataset = numpy.loadtxt(\"pima-indians-diabetes.csv\", delimiter=\",\")\n",
        "# split into input (X) and output (Y) variables\n",
        "X = dataset[:,0:8]\n",
        "Y = dataset[:,8]\n",
        "# create model\n",
        "model = KerasClassifier(build_fn=create_model, epochs=100, batch_size=10, verbose=0)\n",
        "# define the grid search parameters\n",
        "activation = ['softmax', 'softplus', 'softsign', 'relu', 'tanh', 'sigmoid', 'hard_sigmoid', 'linear']\n",
        "param_grid = dict(activation=activation)\n",
        "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1)\n",
        "grid_result = grid.fit(X, Y)\n",
        "# summarize results\n",
        "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
        "means = grid_result.cv_results_['mean_test_score']\n",
        "stds = grid_result.cv_results_['std_test_score']\n",
        "params = grid_result.cv_results_['params']\n",
        "for mean, stdev, param in zip(means, stds, params):\n",
        "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NdcFZPxERFGz",
        "colab_type": "text"
      },
      "source": [
        "# How to Tune Dropout Regularization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lpUnDRC4RGTk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Dropout\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "from keras.constraints import maxnorm\n",
        "# Function to create model, required for KerasClassifier\n",
        "def create_model(dropout_rate=0.0, weight_constraint=0):\n",
        "\t# create model\n",
        "\tmodel = Sequential()\n",
        "\tmodel.add(Dense(12, input_dim=8, kernel_initializer='uniform', activation='linear', kernel_constraint=maxnorm(weight_constraint)))\n",
        "\tmodel.add(Dropout(dropout_rate))\n",
        "\tmodel.add(Dense(1, kernel_initializer='uniform', activation='sigmoid'))\n",
        "\t# Compile model\n",
        "\tmodel.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\treturn model\n",
        "# fix random seed for reproducibility\n",
        "seed = 7\n",
        "numpy.random.seed(seed)\n",
        "# load dataset\n",
        "dataset = numpy.loadtxt(\"pima-indians-diabetes.csv\", delimiter=\",\")\n",
        "# split into input (X) and output (Y) variables\n",
        "X = dataset[:,0:8]\n",
        "Y = dataset[:,8]\n",
        "# create model\n",
        "model = KerasClassifier(build_fn=create_model, epochs=100, batch_size=10, verbose=0)\n",
        "# define the grid search parameters\n",
        "weight_constraint = [1, 2, 3, 4, 5]\n",
        "dropout_rate = [0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
        "param_grid = dict(dropout_rate=dropout_rate, weight_constraint=weight_constraint)\n",
        "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1)\n",
        "grid_result = grid.fit(X, Y)\n",
        "# summarize results\n",
        "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
        "means = grid_result.cv_results_['mean_test_score']\n",
        "stds = grid_result.cv_results_['std_test_score']\n",
        "params = grid_result.cv_results_['params']\n",
        "for mean, stdev, param in zip(means, stds, params):\n",
        "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "34iC3rtHRU26",
        "colab_type": "text"
      },
      "source": [
        "# How to Tune the Number of Neurons in the Hidden Layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YBy2bKRDRV8q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Dropout\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "from keras.constraints import maxnorm\n",
        "# Function to create model, required for KerasClassifier\n",
        "def create_model(neurons=1):\n",
        "\t# create model\n",
        "\tmodel = Sequential()\n",
        "\tmodel.add(Dense(neurons, input_dim=8, kernel_initializer='uniform', activation='linear', kernel_constraint=maxnorm(4)))\n",
        "\tmodel.add(Dropout(0.2))\n",
        "\tmodel.add(Dense(1, kernel_initializer='uniform', activation='sigmoid'))\n",
        "\t# Compile model\n",
        "\tmodel.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\treturn model\n",
        "# fix random seed for reproducibility\n",
        "seed = 7\n",
        "numpy.random.seed(seed)\n",
        "# load dataset\n",
        "dataset = numpy.loadtxt(\"pima-indians-diabetes.csv\", delimiter=\",\")\n",
        "# split into input (X) and output (Y) variables\n",
        "X = dataset[:,0:8]\n",
        "Y = dataset[:,8]\n",
        "# create model\n",
        "model = KerasClassifier(build_fn=create_model, epochs=100, batch_size=10, verbose=0)\n",
        "# define the grid search parameters\n",
        "neurons = [1, 5, 10, 15, 20, 25, 30]\n",
        "param_grid = dict(neurons=neurons)\n",
        "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1)\n",
        "grid_result = grid.fit(X, Y)\n",
        "# summarize results\n",
        "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
        "means = grid_result.cv_results_['mean_test_score']\n",
        "stds = grid_result.cv_results_['std_test_score']\n",
        "params = grid_result.cv_results_['params']\n",
        "for mean, stdev, param in zip(means, stds, params):\n",
        "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}