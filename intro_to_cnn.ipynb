{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "intro-to-cnn.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/morbosohex/Workflow/blob/master/intro_to_cnn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qABx13605gOg",
        "colab_type": "text"
      },
      "source": [
        "The optimizer is specified when you compile the model (in Step 7 of the notebook). \n",
        "\n",
        "'sgd' : SGD\n",
        "\n",
        "'rmsprop' : RMSprop\n",
        "\n",
        "'adagrad' : Adagrad\n",
        "\n",
        "'adadelta' : Adadelta\n",
        "\n",
        "'adam' : Adam\n",
        "\n",
        "'adamax' : Adamax\n",
        "\n",
        "'nadam' : Nadam\n",
        "\n",
        "'tfoptimizer' : TFOptimi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FEpOGNKvdbrp",
        "colab_type": "text"
      },
      "source": [
        "# Convolutional Layers in Keras"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BApKk-E56CXg",
        "colab_type": "code",
        "outputId": "62f3df3d-0019-46de-da12-9957f4ed37bb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from keras.layers import Conv2D"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FtYJalPZeOGu",
        "colab_type": "text"
      },
      "source": [
        "### Arguments\n",
        "\n",
        "- `filters` - number of filters\n",
        "- `kernel_size` - height and width of the convolution window\n",
        "- `strides` - stride of the convolution, if don't specify anything, `strides` is set to 1\n",
        "- `padding` - one of `valid` or `same`, if don't specify anything, `padding` is set to `valid`\n",
        "- `activation` - Typically `relu`, if you don't specify anything, no activation is applied. You are strongly encouraged to add a ReLU activation function to every convolutional layer in your networks.\n",
        "\n",
        "NOTE: It is possible to represent both kernel_size and strides as either a number or a tuple.\n",
        "\n",
        "\n",
        "When using your convolutional layer as the first layer (appearing after the input layer) in a model, you must provide an additional input_shape argument:\n",
        "\n",
        "- `input_shape `- Tuple specifying the height, width, and depth (in that order) of the input.\n",
        "\n",
        "NOTE: Do not include the input_shape argument if the convolutional layer is not the first layer in your network."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OUrZbTcYftOb",
        "colab_type": "text"
      },
      "source": [
        "## Example #1\n",
        "\n",
        "Say I'm constructing a CNN, and my input layer accepts grayscale images that are 200 by 200 pixels (corresponding to a 3D array with height 200, width 200, and depth 1). Then, say I'd like the next layer to be a convolutional layer with 16 filters, each with a width and height of 2. When performing the convolution, I'd like the filter to jump two pixels at a time. I also don't want the filter to extend outside of the image boundaries; in other words, I don't want to pad the image with zeros. Then, to construct this convolutional layer, I would use the following line of code:\n",
        "\n",
        "假设我正在构建CNN，我的输入层接受200 x 200像素的灰度图像（对应于高度为200，宽度为200，深度为1的3D数组）。然后，假设我希望下一层是一个带有16个滤波器的卷积层，每个滤波器的宽度和高度为2.当执行卷积时，我希望滤波器一次跳两个像素,也即步长为2。我也不希望滤波器延伸到图像边界之外;换句话说，我不想用零填充图像。然后，为了构造这个卷积层，我将使用以下代码行："
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NZcCiJRZfsob",
        "colab_type": "code",
        "outputId": "22e43a25-a0e4-4bc2-c063-8b1cb8557437",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        }
      },
      "source": [
        "Conv2D(filters=16, \n",
        "       kernel_size=2,\n",
        "       strides=2,\n",
        "       padding='valid',\n",
        "       activation='relu',\n",
        "       input_shape=(200,200,1))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0718 14:35:10.980968 140640370833280 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.layers.convolutional.Conv2D at 0x7fe918b7a4a8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "99nKKWCtgkOD",
        "colab_type": "text"
      },
      "source": [
        "## Example #2\n",
        "\n",
        "Say I'd like the next layer in my CNN to be a convolutional layer that takes the layer constructed in Example 1 as input. Say I'd like my new layer to have 32 filters, each with a height and width of 3. When performing the convolution, I'd like the filter to jump 1 pixel at a time. I want the convolutional layer to see all regions of the previous layer, and so I don't mind if the filter hangs over the edge of the previous layer when it's performing the convolution. Then, to construct this convolutional layer, I would use the following line of code:\n",
        "\n",
        "假设我希望CNN中的下一层是卷积层，它将示例1中构造的卷积层作为输入。假设我希望我的新图层有32个滤波器，每个滤波器的高度和宽度均为3.当执行卷积时，我希望滤波器一次跳1个像素,即步长为1。我希望卷积层能够看到前一层的所有区域，所以我不介意过滤器在执行卷积时是否挂在前一层的边缘上,即需要进行零填充。然后，为了构造这个卷积层，我将使用以下代码行："
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wbHm11xWgnL4",
        "colab_type": "code",
        "outputId": "877cb5ce-98a7-4cdf-ca4d-37e41fbc851a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "Conv2D(filters=32,\n",
        "      kernel_size=3,\n",
        "      strides=1,\n",
        "      padding='same',\n",
        "      activation='relu')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.layers.convolutional.Conv2D at 0x7fe918b7a908>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kx0-s-NGhBoC",
        "colab_type": "text"
      },
      "source": [
        "## Example #3\n",
        "\n",
        "If you look up code online, it is also common to see convolutional layers in Keras in this format:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XNvd46T8hNs5",
        "colab_type": "code",
        "outputId": "c3ea54fd-b2e4-4543-da57-a099fee96eda",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "Conv2D(64, (2,2), activation='relu')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.layers.convolutional.Conv2D at 0x7fe918b7a438>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pe4CD0BQhTwj",
        "colab_type": "text"
      },
      "source": [
        "In this case, there are 64 filters, each with a size of 2x2, and the layer has a ReLU activation function. The other arguments in the layer use the default values, so the convolution uses a stride of 1, and the padding has been set to 'valid'."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KQbfjASLmsOY",
        "colab_type": "text"
      },
      "source": [
        "# Dimensionality"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CUPnZuFWmxmr",
        "colab_type": "text"
      },
      "source": [
        "-  same as with neural network, create a CNN in keras by first creating a Sequential model\n",
        "- add layers by using `.add()`\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E6Vs6doroIf1",
        "colab_type": "text"
      },
      "source": [
        "This corresponds to the value under Output Shape in the printed output. In the figure above, None corresponds to the batch size, and the convolutional layer has a height of 100, width of 100, and depth of 16."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0PkPQ-e3nI_v",
        "colab_type": "code",
        "outputId": "309dacfa-3fe2-48a7-8671-99a591895706",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        }
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Conv2D(filters=16,\n",
        "                 kernel_size=2,\n",
        "                 strides=2, \n",
        "                 padding='valid',\n",
        "                 activation='relu',\n",
        "                 input_shape=(200,200,1)))\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_12 (Conv2D)           (None, 100, 100, 16)      80        \n",
            "=================================================================\n",
            "Total params: 80\n",
            "Trainable params: 80\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MWtturMFoL-K",
        "colab_type": "text"
      },
      "source": [
        "# Formula: Number of Parameters in a Convolutional Layer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K6nCXXmNoOIC",
        "colab_type": "text"
      },
      "source": [
        "The number of parameters in a convolutional layer depends on the supplied values of filters, kernel_size, and input_shape. Let's define a few variables:\n",
        "\n",
        "- `K` - 滤波器的数量\n",
        "- `F` - 卷积层的高度和宽度\n",
        "- `D_in` - 前一层的深度\n",
        "\n",
        "Notice that `K = filters`, and `F = kernel_size`. Likewise, `D_in` is the last value in the input_shape tuple.\n",
        "\n",
        "each filter: `F*F*D_in` weights\n",
        "\n",
        "there is `K` filters: `K*F*F*D_in`\n",
        "\n",
        "Since there is one bias term per filter, the convolutional layer has `K` biases. Thus, the _ number of parameters_ in the convolutional layer is given by `K*F*F*D_in + K`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eaRAleCqpJFD",
        "colab_type": "text"
      },
      "source": [
        "# Formula: Shape of a Convolutional Layer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "He2VLEjno5vs",
        "colab_type": "text"
      },
      "source": [
        "The shape of a convolutional layer depends on the supplied values of `kernel_size`, `input_shape`, `padding`, and `stride`. Let's define a few variables:\n",
        "\n",
        "- K - 卷积层中滤波器的数量\n",
        "- F - 滤波器的高度与宽度\n",
        "- S - 卷积层的步长\n",
        "- H_in - 前一层的高度\n",
        "- W_in - 前一层的宽度\n",
        "\n",
        "Notice that `K = filters`, `F = kernel_size`, and `S = stride`. Likewise, `H_in` and `W_in` are the first and second value of the input_shape tuple, respectively.\n",
        "\n",
        "The **depth** of the convolutional layer will always equal the number of filters `K`.\n",
        "\n",
        "\n",
        "If `padding = 'same'`, then the spatial dimensions of the convolutional layer are the following:\n",
        "\n",
        "- height = ceil(float(`H_in`) / float(`S`))\n",
        "- width = ceil(float(`W_in`) / float(`S`))\n",
        "\n",
        "If `padding = 'valid'`, then the spatial dimensions of the convolutional layer are the following:\n",
        "\n",
        "- height = ceil(float(`H_in` - `F` + 1) / float(`S`))\n",
        "- width = ceil(float(`W_in` - `F` + 1) / float(`S`))\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iCZTcnrHsiwn",
        "colab_type": "text"
      },
      "source": [
        "# Quiz"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vaVDT43Eq0xS",
        "colab_type": "code",
        "outputId": "685948e8-6412-49a3-efd1-92bfdbaeaf9d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        }
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Conv2D(filters=32, kernel_size=3, strides=2, padding='same', \n",
        "    activation='relu', input_shape=(128, 128, 3)))\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_13 (Conv2D)           (None, 64, 64, 32)        896       \n",
            "=================================================================\n",
            "Total params: 896\n",
            "Trainable params: 896\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o6WBCFMGq2iq",
        "colab_type": "text"
      },
      "source": [
        "#### How many parameters does the convolutional layer have?\n",
        "\n",
        "K = 32\n",
        "F = 3\n",
        "D_in = 3\n",
        "\n",
        "num_of_weights = 32 * 3* 3* 3\n",
        "num_of_bias = 32\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U5iFHFx7pO7J",
        "colab_type": "text"
      },
      "source": [
        "#### What is the depth of the convolutional layer?\n",
        "answer = K"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-kFyT04lqoIC",
        "colab_type": "text"
      },
      "source": [
        "#### What is the width of the convolutional layer?\n",
        "\n",
        "padding='same'\n",
        "\n",
        "S = 2\n",
        "\n",
        "W_in = 128\n",
        "\n",
        "width = ceil(float(W_in)/float(S)) = 64"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_DmlG-HFG-sF",
        "colab_type": "text"
      },
      "source": [
        "# Pooling Layer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YElQgZ9tHQgw",
        "colab_type": "text"
      },
      "source": [
        "池化层的输入是卷积层中不同滤波器产生的特征映射的堆叠, 卷积层可能会因为滤波器的数量巨大,产生的特征映射过多, 导致维度过大, 池化层所扮演的角色就是降低维数\n",
        "\n",
        "两种类型\n",
        "\n",
        "- 最大池化层\n",
        "\n",
        "将一组特征映射作为输入\n",
        "与卷积操作类似,需要获得滤波器,以及滑动步长, 然后对一组特征映射进行平行垂直滑动.\n",
        "\n",
        "最大池化层中对应的节点值的计算方法是: 拿出**窗口**中包含的最大像素\n",
        "\n",
        "输出是一组具有相同数量的特征映射, 但是特征映射的宽和高都减小了\n",
        "\n",
        "- 全局平均池化\n",
        "\n",
        "对于这种类型,不指定窗口大小,也不指定步长\n",
        "\n",
        "对一组特征映射计算每个映射的节点均值, 最终会得到一个向量, 向量数目和特征映射数目相同\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3e3bsN0gMg28",
        "colab_type": "text"
      },
      "source": [
        "## Max Pooling Layers in Keras - 最大池化层-Keras"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kmzDlhdMM6FK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 导入包并且新建最大池化层\n",
        "from keras.layers import MaxPooling2D"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jLx3VGvwNK1B",
        "colab_type": "text"
      },
      "source": [
        "```MaxPooling2D(pool_size,strides,padding)```\n",
        "\n",
        "参数\n",
        "\n",
        "- `pool_size` - 池化窗口的宽和高\n",
        "- `strides` - 滑动步长, 如果不指定, 大小为池化窗口的大小\n",
        "- `padding` - 两个选项`valid`和`same`,如果不指定, 默认不填充\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9H0xGEUbN5ey",
        "colab_type": "text"
      },
      "source": [
        "Example\n",
        "Say I'm constructing a CNN, and I'd like to reduce the dimensionality of a convolutional layer by following it with a max pooling layer. Say the convolutional layer has size (100, 100, 15), and I'd like the max pooling layer to have size (50, 50, 15). I can do this by using a 2x2 window in my max pooling layer, with a stride of 2, which could be constructed in the following line of code:\n",
        "\n",
        "假设我正在构建一个CNN，我想通过跟随最大池层来减少卷积层的维数。假设卷积层的大小（100,100,15），我想最大池层的大小（50,50,15）。我可以通过在我的最大池层中使用2x2窗口来做到这一点，步长为2，可以在以下代码行中构造：\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_dEznzJAOQQ3",
        "colab_type": "code",
        "outputId": "98f12572-5dc8-46c6-ef39-3da840afe5bb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 109
        }
      },
      "source": [
        "MaxPooling2D(pool_size=2, strides=2)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0808 07:55:28.687218 139850996135808 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.layers.pooling.MaxPooling2D at 0x7f314e57b860>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zzHUVfpdOeeK",
        "colab_type": "code",
        "outputId": "ee47abeb-0586-4cb0-a81f-6e28c2ac9472",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        " MaxPooling2D(pool_size=2, strides=1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.layers.pooling.MaxPooling2D at 0x7f314e57b9e8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XfMKym_POlO0",
        "colab_type": "text"
      },
      "source": [
        "## 查看最大池化层的维度"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V2syLBipO9nZ",
        "colab_type": "code",
        "outputId": "eef89f7e-0616-41c6-9df6-97c5a845a061",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 271
        }
      },
      "source": [
        "from keras.layers import MaxPooling2D\n",
        "from keras.models import Sequential\n",
        "\n",
        "model = Sequential()\n",
        "model.add(MaxPooling2D(pool_size=2,strides=2,input_shape=(100,100,15)))\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0808 07:59:39.212870 139850996135808 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "W0808 07:59:39.228593 139850996135808 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "max_pooling2d_3 (MaxPooling2 (None, 50, 50, 15)        0         \n",
            "=================================================================\n",
            "Total params: 0\n",
            "Trainable params: 0\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zxOsi8AyPZIm",
        "colab_type": "text"
      },
      "source": [
        "# CNN - 图像分类"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-0TGCkwbP9NG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPool2D, Flatten, Dense\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Conv2D(filters=16,kernel_size=2,padding='same',activation='relu',\n",
        "                 input_shape=(32,32,3)))\n",
        "model.add(MaxPooling2D(pool_size=2))\n",
        "model.add(Conv2D(filters=32,kernel_size=2,padding='same',activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=2))\n",
        "model.add(Conv2D(filters=64,kernel_size=2,padding='same',activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=2))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(500,activation='relu'))\n",
        "model.add(Dense(10,activation='softmax'))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1VmbCwyrRnP3",
        "colab_type": "text"
      },
      "source": [
        "网络以三个卷积层的序列开始，然后是最大池层。前六层设计用于获取图像像素的输入阵列并将其转换为已挤出所有空间信息的阵列，并且仅保留编码图像内容的信息。然后将阵列展平为CNN的第七层中的矢量。接下来是两个密集层，旨在进一步阐明图像的内容。最后一层为数据集中的每个对象类都有一个条目，并具有softmax激活函数，因此它返回概率。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rUoLRiWHST_D",
        "colab_type": "text"
      },
      "source": [
        "### 注意事项\n",
        "- 始终将ReLU激活功能添加到CNN中的Conv2D层。除了网络中的最后一层，密集层还应具有ReLU激活功能。\n",
        "\n",
        "- 在构建用于分类的网络时，网络中的最后一层应该是具有softmax激活功能的密集层。最终层中的节点数应等于数据集中的类总数。\n",
        "\n",
        "卷积层一般是增加深度\n",
        "\n",
        "池化层一般是减少宽度和高度\n",
        "\n",
        "最终通过卷积-池化多次操作后,得到的高深度低维度数组中的每一个特征映射代表了学到的不同特征,例如是否有轮子,是否有眼睛,是否有腿等等, 然后经过全连接作为特征预测是否是那种类型的图片."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_gW1tthN3lSR",
        "colab_type": "text"
      },
      "source": [
        "# Image Augmentation in Keras\n",
        "只关注图像中是否存在某个对象\n",
        "\n",
        "去除不相关的信息:\n",
        "\n",
        "对象的大小,角度,位置为不相关信息\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DUYfmItCnTuD",
        "colab_type": "text"
      },
      "source": [
        "# Transfer learning\n",
        "\n",
        "迁移学习包括采用预先训练的神经网络并使神经网络适应新的不同数据集。\n",
        "\n",
        "取决于两者：\n",
        "\n",
        "- 新数据集的大小，和\n",
        "- 新数据集与原始数据集的相似性\n",
        "\n",
        "使用转学习的方法会有所不同。主要有四种情况：\n",
        "\n",
        "- 新数据集很小，新数据类似于原始训练数据\n",
        "- 新数据集很小，新数据与原始训练数据不同\n",
        "- 新数据集很大，新数据类似于原始训练数据\n",
        "- 新数据集很大，新数据与原始训练数据不同\n",
        "\n",
        "![image.png](https://upload-images.jianshu.io/upload_images/12735209-81c4505578431b4d.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)\n",
        "\n",
        "大型数据集可能有一百万个图像。一个小数据可能有两千个图像。大数据集和小数据集之间的分界线在某种程度上是主观的。当使用具有小数据集的转移学习时，过度拟合是一个问题。\n",
        "\n",
        "狗的图像和狼的图像将被认为是相似的; 图像将具有共同的特征。花图像的数据集将与狗图像的数据集不同。\n",
        "\n",
        "四个迁移学习案例中的每一个都有自己的方法。在以下部分中，我们将逐一查看每个案例。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MZjN35kkokeT",
        "colab_type": "text"
      },
      "source": [
        "## 示范网络\n",
        "为了解释每种情况如何工作，我们将从通用的预训练卷积神经网络开始，并解释如何针对每种情况调整网络。我们的示例网络包含三个卷积层和三个完全连接的层：\n",
        "\n",
        "![image.png](https://upload-images.jianshu.io/upload_images/12735209-527314469c1c4536.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)\n",
        "\n",
        "以下是卷积神经网络的概括概述：\n",
        "\n",
        "- 第一层将检测图像中的边缘\n",
        "- 第二层将检测形状\n",
        "- 第三个卷积层检测更高级别的特征\n",
        "\n",
        "每个转移学习案例将以不同的方式使用预先训练的卷积神经网络。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fLXigUqgpAQy",
        "colab_type": "text"
      },
      "source": [
        "## 案例1：小数据集，类似数据\n",
        "\n",
        "![案例1：具有相似数据的小数据集.png](https://upload-images.jianshu.io/upload_images/12735209-d8e548e3b1ff5c93.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)\n",
        "\n",
        "如果新数据集很小并且与原始训练数据类似：\n",
        "\n",
        "- 切断神经网络的末端\n",
        "- 添加一个与新数据集中的类数相匹配的新完全连接层\n",
        "- 随机化新的完全连接层的权重; 冻结预训练网络中的所有权重\n",
        "- 训练网络以更新新的完全连接层的权重\n",
        "\n",
        "为了避免过度拟合小数据集，原始网络的权重将保持不变，而不是重新训练权重。\n",
        "\n",
        "由于数据集相似，因此来自每个数据集的图像将具有类似的更高级别的特征。因此，大多数或所有预训练的神经网络层已经包含有关新数据集的相关信息，应该保留。\n",
        "\n",
        "以下是如何可视化这种方法：\n",
        "\n",
        "![image.png](https://upload-images.jianshu.io/upload_images/12735209-350a3d3d4f327829.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OZySxtGJvr9W",
        "colab_type": "text"
      },
      "source": [
        "## 案例2：小数据集，不同数据\n",
        "\n",
        "![image.png](https://upload-images.jianshu.io/upload_images/12735209-7775bd3a0d223a25.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)\n",
        "\n",
        "如果新数据集很小且与原始训练数据不同：\n",
        "\n",
        "- 切断网络开始附近的大多数预训练层\n",
        "- 向剩余的预训练层添加一个新的完全连接层，该层与新数据集中的类数相匹配\n",
        "- 随机化新的完全连接层的权重; 冻结预训练网络中的所有权重\n",
        "- 训练网络以更新新的完全连接层的权重\n",
        "\n",
        "由于数据集很小，过度拟合仍然是一个问题。为了防止过度拟合，原始神经网络的权重将保持不变，就像第一种情况一样。\n",
        "\n",
        "但是原始训练集和新数据集不共享更高级别的功能。在这种情况下，新网络将仅使用包含较低级别功能的图层。\n",
        "\n",
        "以下是如何可视化此方法：\n",
        "\n",
        "![image.png](https://upload-images.jianshu.io/upload_images/12735209-9090d6bf51b75ed9.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OvC1rwvzvu7L",
        "colab_type": "text"
      },
      "source": [
        "## 案例3：大数据集，类似数据\n",
        "\n",
        "![image.png](https://upload-images.jianshu.io/upload_images/12735209-cfab7b4676fded90.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)\n",
        "\n",
        "如果新数据集很大并且与原始训练数据类似：\n",
        "\n",
        "- 删除最后一个完全连接的图层，并替换为与新数据集中的类数相匹配的图层\n",
        "- 随机初始化新的完全连接层中的权重\n",
        "- 使用预先训练的权重初始化其余权重\n",
        "- 重新训练整个神经网络\n",
        "\n",
        "在对大型数据集进行培训时，过度拟合并不是一个问题; 因此，您可以重新训练所有重量。\n",
        "\n",
        "由于原始训练集和新数据集共享更高级别的特征，因此也使用整个神经网络。\n",
        "\n",
        "以下是如何可视化此方法：\n",
        "\n",
        "![image.png](https://upload-images.jianshu.io/upload_images/12735209-3a5eb409b409538b.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fg8BRHxxwnE0",
        "colab_type": "text"
      },
      "source": [
        "## 案例4：大数据集，不同数据\n",
        "\n",
        "![image.png](https://upload-images.jianshu.io/upload_images/12735209-569c178fad5bcbbd.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)\n",
        "\n",
        "如果新数据集很大且与原始训练数据不同：\n",
        "\n",
        "- 删除最后一个完全连接的图层，并替换为与新数据集中的类数相匹配的图层\n",
        "- 使用随机初始化的权重从头开始重新训练网络\n",
        "- 或者，您可以使用与“大型和类似”数据案例相同的策略\n",
        "\n",
        "\n",
        "即使数据集与训练数据不同，从预训练的网络初始化权重可能会使训练更快。因此，这种情况与具有大型类似数据集的情况完全相同。\n",
        "\n",
        "如果使用预先训练的网络作为起点不能产生成功的模型，另一种选择是随机初始化卷积神经网络权重并从头开始训练网络。\n",
        "\n",
        "以下是如何可视化此方法：\n",
        "\n",
        "![image.png](https://upload-images.jianshu.io/upload_images/12735209-407d8ebc3a1de52a.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bIksw1h9oiW8",
        "colab_type": "text"
      },
      "source": [
        "# Transfer Learning in Keras"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dYG2_lEADT1X",
        "colab_type": "text"
      },
      "source": [
        "## 1. Load Dog Dataset\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r6f6FPC4D9DF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.datasets import load_files       \n",
        "from keras.utils import np_utils\n",
        "import numpy as np\n",
        "from glob import glob\n",
        "\n",
        "# define function to load train, test, and validation datasets\n",
        "def load_dataset(path):\n",
        "    data = load_files(path)\n",
        "    dog_files = np.array(data['filenames'])\n",
        "    dog_targets = np_utils.to_categorical(np.array(data['target']), 133)\n",
        "    return dog_files, dog_targets\n",
        "\n",
        "# load train, test, and validation datasets\n",
        "train_files, train_targets = load_dataset('dogImages/train')\n",
        "valid_files, valid_targets = load_dataset('dogImages/valid')\n",
        "test_files, test_targets = load_dataset('dogImages/test')\n",
        "\n",
        "# load ordered list of dog names\n",
        "dog_names = [item[25:-1] for item in glob('dogImages/train/*/')]\n",
        "\n",
        "# print statistics about the dataset\n",
        "print('There are %d total dog categories.' % len(dog_names))\n",
        "print('There are %s total dog images.\\n' % str(len(train_files) + len(valid_files) + len(test_files)))\n",
        "print('There are %d training dog images.' % len(train_files))\n",
        "print('There are %d validation dog images.' % len(valid_files))\n",
        "print('There are %d test dog images.'% len(test_files))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HguMp2ZODWF3",
        "colab_type": "text"
      },
      "source": [
        "## 2. Visualize the First 12 Training Images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yUIHt9hkENuP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "def visualize_img(img_path, ax):\n",
        "    img = cv2.imread(img_path)\n",
        "    ax.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
        "    \n",
        "fig = plt.figure(figsize=(20, 10))\n",
        "for i in range(12):\n",
        "    ax = fig.add_subplot(3, 4, i + 1, xticks=[], yticks=[])\n",
        "    visualize_img(train_files[i], ax)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aDIGZQcwDX1N",
        "colab_type": "text"
      },
      "source": [
        "## 3. Obtain the VGG-16 Bottleneck Features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "21Bi0a3oES6V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "bottleneck_features = np.load('bottleneck_features/DogVGG16Data.npz')\n",
        "train_vgg16 = bottleneck_features['train']\n",
        "valid_vgg16 = bottleneck_features['valid']\n",
        "test_vgg16 = bottleneck_features['test']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nE5HGZP0DZB9",
        "colab_type": "text"
      },
      "source": [
        "## 4. Define a Model Architecture (Model 1)\n",
        "此处得新全连接层得输入shape(7,7,512)是如何得到得呢?\n",
        "\n",
        "答: 此处需要对预训练模型截断处得输出进行检查,查看输出shape, 方法如下\n",
        "\n",
        "---\n",
        "#### 4.1 导入预训练模型(完整模型)\n",
        "```\n",
        "from keras.applications.vgg16 import VGG16\n",
        "model = VGG16()\n",
        "model.summary()\n",
        "```\n",
        "\n",
        "####  4.2 查看预训练模型不经过修改,最后的输出shape\n",
        "```\n",
        "model.predict(img_input).shape\n",
        "```\n",
        "\n",
        "    对于此网络，model.predict返回1000维概率向量，其中包含图像返回1000个ImageNet类别中的每一个的预测概率。通过img_input通过模型获得的输出的维数是（8,1000）。第一个值8仅表示8个图像通过网络。\n",
        "\n",
        "#### 4.3 导入去除最后一层全连接层的预训练模型\n",
        "```\n",
        "from keras.applications.vgg16 import VGG16\n",
        "model = VGG16(include_top=False)\n",
        "model.summary()\n",
        "```\n",
        "\n",
        "#### 4.4 获取截断层的输出shape\n",
        "```\n",
        "print(model.predict(img_input).shape)\n",
        "```\n",
        "    现在，存储在模型中的网络是VGG-16网络的截断版本，其中最后三个完全连接的层已被删除。在这种情况下，model.predict返回对应于VGG-16的最终最大池化层的3D阵列（尺寸为7×7×512）。通过img_input通过模型获得的输出的维数是（8,7,7,512）。第一个值8仅表示8个图像通过网络。\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XTtknUx7FYo-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.layers import Dense, Flatten\n",
        "from keras.models import Sequential\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Flatten(input_shape=(7, 7, 512)))\n",
        "model.add(Dense(133, activation='softmax'))\n",
        "model.compile(loss='categorical_crossentropy', optimizer='rmsprop', \n",
        "                  metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zXq7ZzgbFSYd",
        "colab_type": "text"
      },
      "source": [
        "## 5. Define another Model Architecture (Model 2)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O_h5lkaDFecN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.layers import GlobalAveragePooling2D\n",
        "\n",
        "model = Sequential()\n",
        "model.add(GlobalAveragePooling2D(input_shape=(7, 7, 512)))\n",
        "model.add(Dense(133, activation='softmax'))\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WfbFG_8lFSqU",
        "colab_type": "text"
      },
      "source": [
        "## 6. Compile the Model (Model 2)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YvI5_BuUFmv8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(loss='categorical_crossentropy', optimizer='rmsprop', \n",
        "                  metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VEMfrswpFS-0",
        "colab_type": "text"
      },
      "source": [
        "## 7. Train the Model (Model 2)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lKALV2w7FnLv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.callbacks import ModelCheckpoint   \n",
        "\n",
        "# train the model\n",
        "checkpointer = ModelCheckpoint(filepath='dogvgg16.weights.best.hdf5', verbose=1, \n",
        "                               save_best_only=True)\n",
        "model.fit(train_vgg16, train_targets, epochs=20, validation_data=(valid_vgg16, valid_targets), \n",
        "          callbacks=[checkpointer], verbose=1, shuffle=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r1Y8VxEyFTRL",
        "colab_type": "text"
      },
      "source": [
        "## 8. Load the Model with the Best Validation Accuracy (Model 2)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mAxW4k0sxHbH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# load the weights that yielded the best validation accuracy\n",
        "model.load_weights('dogvgg16.weights.best.hdf5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PDqL099NGKYK",
        "colab_type": "text"
      },
      "source": [
        "## 9. Calculate Classification Accuracy on Test Set (Model 2)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OxNcLjvHGJzN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# get index of predicted dog breed for each image in test set\n",
        "vgg16_predictions = [np.argmax(model.predict(np.expand_dims(feature, axis=0))) \n",
        "                     for feature in test_vgg16]\n",
        "\n",
        "# report test accuracy\n",
        "test_accuracy = 100*np.sum(np.array(vgg16_predictions)==\n",
        "                           np.argmax(test_targets, axis=1))/len(vgg16_predictions)\n",
        "print('\\nTest accuracy: %.4f%%' % test_accuracy)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}